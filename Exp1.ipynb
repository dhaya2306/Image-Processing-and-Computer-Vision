{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdbadb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\aishw\\anaconda3\\lib\\site-packages (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395d053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\aishw\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06669269",
   "metadata": {},
   "source": [
    "# 1.read,write,show an image and video file\n",
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce7065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6806641",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('game.jpg')\n",
    "cv2.imshow('output',image)\n",
    "\n",
    "cv2.imwrite('gamm.jpeg',image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395b7df",
   "metadata": {},
   "source": [
    "# video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac1b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video or error reading frame.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = 'Cheetah walking.mp4'  # Path to the input video file\n",
    "output_file = 'output_video.avi'  # Path to save the processed video\n",
    "\n",
    "# Open the input video file\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the width, height, and frames per second (FPS) of the input video\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create VideoWriter object for output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can choose other codecs as well\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "# Read and display each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # Read a new frame\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Write the frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Press 'q' to quit the video display\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video objects and close display window\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c78c7",
   "metadata": {},
   "source": [
    "EXP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bbf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image and convert it to grayscale\n",
    "image = cv2.imread('shapes.png')  # Replace with your image file path\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# Line Detection using Hough Line Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=50, maxLineGap=10)\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw lines in green\n",
    "\n",
    "# Circle Detection using Hough Circle Transform\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50, param1=100, param2=30, minRadius=10, maxRadius=100)\n",
    "if circles is not None:\n",
    "    for x, y, r in np.round(circles[0, :]).astype(\"int\"):\n",
    "        cv2.circle(image, (x, y), r, (255, 0, 0), 2)  # Draw circles in blue\n",
    "\n",
    "# Ellipse Detection\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for cnt in contours:\n",
    "    if len(cnt) >= 5:\n",
    "        ellipse = cv2.fitEllipse(cnt)\n",
    "        cv2.ellipse(image, ellipse, (0, 0, 255), 2)  # Draw ellipses in red\n",
    "\n",
    "# Show the image with detected shapes\n",
    "cv2.imshow(\"Detected Shapes\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219ef94",
   "metadata": {},
   "source": [
    "Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cbc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('game.jpg')  # Replace with your image file path\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian filter\n",
    "gaussian_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply Median filter\n",
    "median_blur = cv2.medianBlur(gray, 5)\n",
    "# Display the results\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Gaussian Blur\", gaussian_blur)\n",
    "cv2.imshow(\"Median Blur\", median_blur)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2bdecd",
   "metadata": {},
   "source": [
    "Exp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0631fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image and convert it to grayscale\n",
    "image = cv2.imread('game.jpg')  # Replace with your image file path\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply binary thresholding to prepare for contour detection\n",
    "_, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on the original image\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 2)  # Draw contours in green\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"Contours\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f1df6",
   "metadata": {},
   "source": [
    "Exp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c606e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture('Cheetah walking.mp4')\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    fgMask = backSub.apply(frame)\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fgMask)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa5a09",
   "metadata": {},
   "source": [
    "Exp7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60800c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sunset.mp4')  # Replace with your video file path, or use 0 for webcam\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction to get the foreground mask\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "    # Find contours in the foreground mask\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw bounding boxes around detected objects\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # Filter out small objects\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw rectangle in green\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Object Tracking', frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bceed",
   "metadata": {},
   "source": [
    "Exp 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c571d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifiers for face and smile detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "# Function to perform smile detection\n",
    "def detect_smile(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25))\n",
    "\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Load the image\n",
    "image_path = 'image.jpg'\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Perform smile detection\n",
    "canvas = detect_smile(gray, frame)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Smile Detection', canvas)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8c905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2c65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
